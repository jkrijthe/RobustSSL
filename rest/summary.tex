\chapter{Summary}
{\LARGE{\textsf{\MakeUppercase{Robust Semi-supervised Learning}}}}
\\[12pt]
Through advances in sensor, storage and communication technology and adoption of digital technology in every aspect of our lives, large amounts of data are routinely gathered. Statistical learning from data, in many cases, requires a specific type of datum: \emph{labeled} examples for which we know both the input and some outcome we would like to predict. The problem of semi-supervised learning is how to use, increasingly abundantly available, \emph{unlabeled} examples to improve supervised learning methods that typically only consider labeled examples.

One of the issues of semi-supervised learning methods is that adding unlabeled data, unlike our experience in the supervised paradigm, does not guarantee improved performance, nor do we understand very well when semi-supervised learning will be helpful. \emph{Robust} or \emph{safe} semi-supervised methods are those that attempt to ensure performance of a semi-supervised method is at least as good as its supervised counterpart. 

It is often assumed particular assumptions need to be made to allow for semi-supervised learning to be possible at all. Yet these assumptions may also be the cause of a decrease in performance. The main claim brought forth by this thesis is that, by avoiding these assumptions, for some classifiers, it it possible to construct robust semi-supervised classifiers, when we consider performance in terms of the so-called surrogate loss that the supervised classifier is optimizing and we measure performance on the labeled and unlabeled data. We also consider, for the class of classifiers defined by a margin-based loss function, under what conditions such improvements are possible, and for which methods such improvements are inherently impossible to obtain.

In the first part of this thesis, we show that by implicitly considering all possible labelings of the unlabeled data and the corresponding classifiers, and projecting the supervised solution unto this set of solutions, it is possible to construct a semi-supervised version of the least squares classifier, which, under strict theoretical conditions can be considered safe. We apply the same framework to linear discriminant analysis to show this idea can also be applied to other classifiers. Subsequently, by changing the distance measure used in the projection, we construct a procedure for the least squares classifier that is guaranteed to improve performance under much weaker conditions. This is the first method for which such strict improvement guarantees can be provided.

In practice, the performance of classification models is often evaluated in terms of the classification error, area under the ROC curve, F-score or other measures that consider the number of mistakes the classifier makes in one way or the other. On the other hand, the guarantees given in Part One of this thesis are in terms of the surrogate loss of a classifier. In Part Two, we consider these surrogate losses to show that they are interesting quantifies to study in their own right. We then prove it is impossible to construct any semi-supervised learner that guarantees the strong notion of robust/safe semi-supervised learning from Part One for a large class of common supervised algorithms defined by monotonically decreasing margin-based loss functions. This sheds additional light on the (im)possibilities of semi-supervised learning in general, and safe semi-supervised learning in particular.

Continuing with the squared loss of Part One, we construct a simple formulation of the well-known self-learning approach to semi-supervised learning, for the least squares classifier. A slight adaptation of this formulation leads to a type of soft-label self-learning which is shown to outperform the hard-label self-learning variant in many cases. While for these self-learning methods there are no safety guarantees, such as for the methods in Part One, these ideas are often applied in practice, and we show how this can be properly formulated and analyzed for the least squares classifier.

In some of the experiments carried out in this thesis, we find that a peaking phenomenon occurs. This is known to occur for some supervised classifiers, where, when there are fewer training examples than features, the error first increases as we add more data before it decreases again. We observe that a similar phenomenon occurs in the semi-supervised setting in a more extreme form. We argue the difference in severity between the supervised and semi-supervised setting can be explained by a lack of updating of the estimate of the class means while the intrinsic dimensionality of the problem grows. We also consider under what conditions the semi-supervised classifier recovers from the bad performance at the peak, as we add more unlabeled data.

Finally, in Part Three, we cover the reproducibility and replicability of the results uncovered in the course of this research programme and in pattern recognition research in general. We argue that reproducibility has many advantages which often outweigh the cost, but that this should not lead to complacency about replicating results, which in pattern recognition research, often means re-implementing methods. Additionally, we introduce a software package that can be used to reproduce the results presented in this thesis, and to replicate various well-known results in the semi-supervised learning.

Overall, the result of the work covered in this thesis is a new look at the possibilities and impossibilities for (robust) semi-supervised learning, and a novel perspective on using projections of estimators to construct these methods. As statistical learning starts to pervade many parts society, and unlabeled data become increasingly available, making use of this data and understanding its possibilities and limitations remains an important topic. As statistical models become more complex, the basic questions remain the same, questions whose answers we hope to have contributed to in this work.

\begin{otherlanguage}{dutch}
\chapter{Samenvatting}
{\LARGE{\textsf{\MakeUppercase{Robuust Semi-begeleid Leren}}}}
\\[12pt]
Door vooruitgang in technologie voor het meten, opslaan en delen van gegevens en door de toepassing van digitale technologie in alle facetten van ons leven, worden grote hoeveelheden gegevens op grote schaal verzameld. Om hier statistisch van te kunnen leren is een specifiek soort gegevens nodig: gelabelde voorbeelden waarvan de invoer en de gewenste uitkomst die we willen voorspellen bekend is. De uitdaging van semi-begeleid leren is hoe ongelabelde voorbeelden, die in steeds grotere hoeveelheden beschikbaar zijn, gebruikt kunnen worden om methoden voor begeleid leren, die typisch enkel leren van gelabelde voorbeelden, te verbeteren.

Een van de problemen met semi-begeleide methoden is dat het toevoegen van ongelabelde voorbeelden niet altijd leidt tot een verbetering van de resultaten, in tegenstelling tot begeleid leren. Bovendien is er beperkt begrip over in welke situaties semi-begeleide methoden wel werken. \emph{Robuuste} of \emph{Veilige} semi-begeleide methoden zijn methoden die een garantie proberen te geven dat de prestaties van een semi-begeleid algoritme minstens zo goed zijn als die van zijn (volledig-)begeleide tegenhanger.

Er wordt vaak aangenomen dat specifieke vooronderstellingen nodig zijn om semi-begeleid leren mogelijk te maken. Deze vooronderstellingen zijn tevens een mogelijke oorzaak voor de slechtere resultaten. De voornaamste stelling in dit proefschrift is dat het, door het vermijden van deze aannames, mogelijk is om robuuste semi-begeleide classificatie algoritmen te construeren. Hierbij meten we de prestaties van een algoritme in termen van een zogenaamde surrogaat verliesfunctie die door een begeleid classificatie algoritme wordt geoptimaliseerd en meten de prestaties op de gelabelde en ongelabelde voorbeelden. Naast de constructie van dergelijke robuuste algoritmen laten we zien onder welke voorwaarden robuuste prestatieverbeteringen mogelijk zijn, voor de klasse van classificatie algoritmen die gedefinieerd worden door middel van op de marge gebaseerde verliesfuncties, en voor welke methoden zulke verbeteringen inherent onmogelijk zijn.

In het eerste deel van dit proefschrift laten we zien dat door het impliciet bekijken van alle mogelijke labelings van de ongelabelde voorbeelden en de bijbehorende classificatie functies, en het projecteren van de begeleid-leren oplossing op deze verzameling van functies, het mogelijk is een semi-begeleide versie van het minste kwadratische afwijking classificatie algoritme te construeren. Onder strikte theoretische voorwaarden kan deze versie als veilig worden beschouwd. We passen dit zelfde conceptuele raamwerk toe op lineaire discriminanten analyse om te laten zien dat dit idee ook toegepast kan worden voor andere classificatie algoritmen. Vervolgens construeren we een alternatieve procedure voor de minste kwadratische afwijking methode door een andere afstandsmaat toe te passen om de projectie uit te voeren. Voor deze procedure kan onder veel mildere voorwaarden worden aangetoond dat deze de prestaties gegarandeerd niet verslechterd ten opzichte van de begeleide methode. Dit is de eerste procedure waarvoor een dergelijke strikte garantie gegeven kan worden.

In de praktijk worden de prestaties van classificatiemethoden vaak gemeten aan de hand van de classificatie fout, de oppervlakte onder de ROC curve, de F-score of andere maatstaven die gerelateerd zijn aan de classificatie fout. De garanties die in het eerste deel van dit proefschrift zijn afgeleid gelden echter voor de surrogaat verliesfunctie van de classificatie methode. In deel twee van het proefschrift kijken we naar deze surrogaten en laten we zien dat dit objecten zijn die op zichzelf interessant zijn om te bestuderen. Vervolgens bewijzen we dat het onmogelijk is om semi-begeleide versies te verzinnen die de strikte garanties uit deel een van het proefschrift kunnen geven voor een grote klasse aan veel gebruikte begeleid leren methoden. Deze klasse bestaat uit methoden die gedefinieerd worden door op de marge gebaseerde verliesfuncties. Dit resultaat werpt licht op de (on)mogelijkheden van semi-begeleid leren in het algemeen en veilig/robuust semi-begeleid leren in het bijzonder.

Voor de kwadratische verliesfunctie die we veelvuldig bekijken in het eerste deel van het proefschrift leiden we een simpele formulering af voor een semi-begeleide variant die overeenkomt met een zachte-label variant van de bekende zelf-leer aanpak. We laten zien dat deze methode over het algemeen beter presteert dan de harde-label variant van zelf-leren. Hoewel we voor deze methode geen garanties kunnen bieden zoals in de eerdere hoofdstukken van het proefschrift, relateert deze aanpak aan veelgebruikte methoden in de praktijk. Hiervoor laten we zien hoe deze op een juiste wijze geformuleerd en bestudeerd kunnen worden.

In een aantal experimenten in het proefschrift observeerden wij een zogenaamd piek fenomeen. Dit fenomeen is bekend bij begeleide classificatie methoden, waar, wanneer minder voorbeelden dan eigenschappen van deze voorbeelden beschikbaar zijn, de classificatie fout eerst toeneemt en vervolgens af neemt als extra voorbeelden aan het leerproces worden toegevoegd. Wij observeren een gelijksoortig fenomeen in het semi-begeleide geval, maar in extremere vorm. We beargumenteren dat dit verschil in de grootte van het piek fenomeen verklaard kan worden door het gebrek aan extra informatie over de gemiddelden van de verschillende klassen, terwijl de intrinsieke dimensionaliteit van het probleem groeit. We laten tevens zien onder welke voorwaarden de semi-begeleide methode herstelt van de hoge classificatie fout van de piek door het toevoegen van grote hoeveelheden ongelabelde voorbeelden.

Ten slotte besteden we in deel drie van het proefschrift aandacht aan de reproduceerbaarheid en replicatie van onderzoeksresultaten in ons onderzoek en patroonherkenningsonderzoek in het algemeen. We laten zien dat reproduceerbaarheid vele voordelen heeft die vaak opwegen tegen de kosten, maar dat we er zorg voor moeten dragen dat dit niet leidt tot een verminderde inzet voor het repliceren van resultaten, wat in patroonherkenningsonderzoek vaak neerkomt op het opnieuw implementeren van bestaande methoden. Daarnaast presenteren we een softwarepakket om de resultaten in dit proefschrift te reproduceren en om het gemakkelijker te maken om bekende resultaten uit de literatuur te repliceren.

Het resultaat van het werk beschreven in dit proefschrift is een nieuwe kijk op de mogelijkheden en beperkingen van (robuust) semi-begeleid leren, en een nieuw perspectief op het construeren van methoden door het gebruik van projecties van schatters van model parameters. Nu statistische leermethoden doordringen in grote delen van onze maatschappij en ongelabelde gegevens in grotere hoeveelheden beschikbaar komen, blijft het begrip van de mogelijkheden en beperkingen van dit soort data een belangrijk onderwerp. Ook nu de gebruikte statistische modellen steeds complexer worden, blijven de fundamentele vragen in de statistiek dezelfde. We hopen bijgedragen te hebben aan de antwoorden op deze vragen door middel van dit proefschrift. 
\end{otherlanguage}
