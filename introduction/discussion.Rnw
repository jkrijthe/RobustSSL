<<set-parent-discussion, echo=FALSE, cache=FALSE>>=
set_parent('../thesis.Rnw')
@

\chapter[Discussion]{Discussion}

Given the increasing amounts of available (unlabeled) data, semi-supervised learning is an important practical problem. What is more, it is an interesting theoretical problem because it gets at the heart of the value of different types of information in estimating statistical models. The results in the previous chapters contribute to a better understanding of the limits of semi-supervised learning as well as introduce robust methods that guarantee improvements over the supervised alternative. In this final part of the thesis, let us revisit the main findings in the broader perspective of the research questions considered in the introduction.

\section{Semi-supervised Learning without Additional Assumptions}
One of the basic tenets in semi-supervised learning research has been that learning without additional assumptions about the relationship between $p_X$ and $p_{Y|X}$ is impossible. The results in \Cref{chapter:icls,chapter:iclda,chapter:projection,chapter:marginbased} nuance this view. For some supervised classifiers, guaranteed improvements are possible in terms of the surrogate loss on the labeled and unlabeled data. For other supervised methods, these guarantees are essentially impossible. To us, this suggests that taking into account the way supervised models are fitted, and recognizing the finite sample available, leads to different views on the possibilities of semi-supervised learning than considering models that are correctly specified. In practice, models are never perfect, and unlabeled data can be one way to correct some of these imperfections.

\section{Improvement Guarantees}
The improvement guarantees that we offer in \Cref{chapter:projection} are the first of their kind: they guarantee performance will not degrade for any possible labeling of the unlabeled data. The setting considered, however, does not necessarily correspond to generalization performance in terms of the error rate. 

Firstly, we make a claim about performance on the labeled and unlabeled data, rather than some unseen test set. In case the size of the unlabeled set grows to infinity, this guarantee converges to a generalization guarantee. Alternatively, the results can be adapted to the transductive setting where one is interested in predictions on a specific unlabeled set of objects. 

Nonetheless, it is interesting that we never use the assumption that the unlabeled data originate from the same distribution as the labeled data. A way forward to get to more general guarantees is to take this assumption into account while letting go of the requirement that the supervised solution is not better than the semi-supervised solution for every possible dataset with probability one.

A second property of the improvement guarantee considered in this work is that it is in terms of the surrogate loss of the supervised classifier. The reason we think this makes an interesting guarantee is two fold. For one, it guarantees that we construct a true semi-supervised version of the supervised classifier by ensuring we do well in terms of the criterion we would be optimizing if we did have the labels of the unlabeled objects. Secondly, for some of the supervised models, even for increasing  numbers of \emph{labeled} objects we can not guarantee classification performance increases, while they do improve in terms of the surrogate loss. ``Improving'' a classifier using unlabeled data should, therefore, be evaluated in terms of this measure, or the improved procedure is best considered a totally different method than the original supervised procedure.

It is important to consider what the improvement guarantee means for the loss for specific objects in the unlabeled set. Especially in the presence of outliers, a change in the classifier can lead to a higher loss for almost every observation, except for a few observations where the loss is reduced by a large amount. This is a consequence of considering the loss on all objects together, and has an effect similar to what one observes in James-Stein estimators \citep{Efron1977}, where these estimators dominate estimators that do not consider the loss on all objects simultaneously.

Instead of the surrogate loss, one could only be interested in getting improved classification performance. As mentioned, even in the supervised case, we do not minimize this loss directly. The goal in this thesis is to construct semi-supervised versions of common supervised procedures that are guaranteed to not perform worse. Since these supervised procedures consider surrogate losses, it makes sense to consider these same losses in the semi-supervised case. We may still be able to get performance guarantees in terms of the classification error through generalization bounds, similar to the supervised setting. While we guarantee performance improvements for any number of labeled objects, the effect of the unlabeled data may diminish as more labeled examples are added. As such, unlabeled data may have no effect on the convergence rate, as conjectured by \cite{Ben-David2008}. 

\section{On the Impossibility of Safe Semi-supervised Learning}
For a number of common supervised methods, the results in \Cref{chapter:marginbased} show that our notion of safe semi-supervised learning is inherently impossible. This is contrary to earlier claims for some of these models, such as for the support vector machine \cite{Li2015}. Our definition of safety, is conservatively strict: the supervised solution has to not be better than the semi-supervised procedure for any possible labeling of the unlabeled data. Compare this to the claim of \citet{Li2015} where this only has to hold for a labeling that is generated by a low-density separator. The claim we make is that, true safety concerns all possible contingencies, and this type of semi-supervised learning may well be impossible, in line with what others have claimed. It is all the more surprising, then, that for some classifiers, this notion of safety does lead to useful semi-supervised procedures.

\section{Thoughts on the Least Squares Classifier}
The reasons for measuring performance in terms of the surrogate loss have been outlined above. But in the thesis, we often considered one particular surrogate loss: the squared loss. This loss allowed us to derive simple, convex problems to obtain the semi-supervised estimator with interesting performance guarantees. These improvements, however, might only tell us something about the squared loss, and not about the classification problem we are trying to solve at all. One particular property of the squared loss is that the loss for an object may increase if the magnitude of the decision function is increased even when the object is correctly classified. Any improvements that we get, therefore, might ``improve'' the decision function in ways that have little to do with the classification problem. Furthermore, as we saw in the chapter on peaking, the least squares classifier can behave erratically when we have only little data compared to the number of features. The gains in classification performance that we do observe empirically, may just be because of the slight regularizing effect that the semi-supervised procedure has on a very unstable classifier. Nevertheless, this improvement is \emph{guaranteed}, and it is more than we might have been able to hope for, given the extremely strict conditions under which we consider safe improvements.

\section{Projections and Minimax Principles}
Within the projection framework we showed in \Cref{chapter:marginbased} that for many supervised methods the constraint set is basically too large to put any useful constraint on the semi-supervised solution. Leaving this issue of the size of the constraint set aside for now, there is the additional question what distance measure should be employed for losses other than the squared loss. This measure is important since it not only determines what semi-supervised solution is selected by determining the closest solution to the supervised solution within the constraint set, but also determines in what sense we are closer to the oracle solution. As of yet, we have no definite suggestion on how this should be solved. Initially, for some models, one might expect the KL-divergence to be a promising candidate. Unfortunately, the simple proof in \Cref{chapter:projection} does not directly apply in that case, since it is not a proper distance metric. 

An answer may be found in an equivalent (for the least squares case) formulation proposed by \citet{Loog2016}. One can show the projection is equivalent to finding the solution that minimizes the difference in loss between the supervised and semi-supervised solutions over all possible assignments of responsibilities of unlabeled objects to classes. For similar connections in a different problem see \citet{Arnold2000}. By using this minimax formulation for other classifiers and finding a distance measure that (approximately) leads to the same optimization problem, we may be able to generalize the projection procedure to other losses.

It is important to note that the novelty of the projection procedure proposed here is not in finding some solution within the constraint set -- self-learning, by definition, does this as well -- but by defining which solution to select from the set and the properties that follow. For instance, looking at the problem from the viewpoint of projections suggests how to improve semi-supervised estimators for which the implicit constraints are too loose. It suggests the constraint space is too large and we should somehow decrease its size. This has some correspondence with the basic intuition behind many semi-supervised approaches covered in the introduction which assume the unlabeled data limit the hypotheses that should be considered. A nice property of the implicit constraints is that they are guaranteed to contain the solution corresponding to the true labeling, which in turn can guarantee non-degradation of the semi-supervised estimator. But letting go of our strict notion of non-degradation, one could construct constraint sets that contain the oracle with high probability, but which are much smaller than the implicit constraints set. In experiments we conducted, assuming information about the proportion of objects of each class did not lead to large improvements in performance, but other such assumptions might.

One of the nice properties of the squared loss is that it leads to a closed form solution if we know the labels. This, in turn, leads to an efficient way to move through the constraint set to calculate the projection. For other losses this may be more difficult to achieve, but using tools like the implicit function theorem to deal with the constraints, one may still be able to find a reasonable formulation of the problem. In general, however, the computation of the projection does not scale well in terms of the number of unlabeled examples. Approximations to the constraint set may alleviate some of the computational burden without introducing a high probability of lowering performance.

\section{Semi-supervised Learning in Practice}
While the results in this thesis offer both insights into the semi-supervised learning problem and methods that guarantee performance improvements, in practice, we might be willing to forego some of this certainty if this means we might get large improvements in performance for many problems. We will first consider whether performance degradation is actually a problem and then make some comments about the future of semi-supervised learning in machine learning research and practice. 

\subsection{Conservatism}
In this thesis, we have taken an extremely conservative view to semi-supervised learning: because the semi-supervised solution might lead to worse performance than the supervised solution, we should explicitly construct methods that guard against this.

One of the reasons for considering these types of methods is that it may be hard to detect when semi-supervised learning is failing and fall back on a supervised methods, especially given the limited amounts of labeled data available. Many semi-supervised methods have been developed and shown to be effective by illustrating performance improvements for the most effective settings of the hyperparameters that are introduced, when effectiveness is evaluated based on the test set. This is not how one can apply these methods in practice, however, where hyperparameters and algorithms have to be selected based on the data at hand. We do not have a good grasp of how big this selection problem is in practice. How often will the wrong setting be selected and result in decreased performance? A big step forward to answer this question would be a large scale study over both datasets and methods to characterize the size of this problem, or whether it is a problem at all. One attempt has been made by \citet{Goldberg2009}, for two semi-supervised methods, which suggests the semi-supervised methods outperform the supervised method in the majority of cases when the hyperparameters are selected using cross-validation, but still lead to degradations in performance on a significant number of occasions. Studying this for a broader set of methods and datasets will give us some indication whether conservatism is mostly theoretically interesting or a practical necessity.

\subsection{Automatically Correct Methods}
This classifier selection problem also relates to the goal of constructing conservative methods: our ultimate goal is to construct methods that work ``automatically'', just like in the supervised case, where adding more data typically leads to better decision functions, or understand when this is not possible. As of yet, it is unclear whether this can also be achieved through some cross-validation strategy. Yet, even if it could, having methods automatically ensure this property has both advantages in understanding the limits of these methods, as shown in this thesis, and possible computational advantages.

\subsection{Violations of Basic Conditions}
As we noted in the introduction of this thesis, in semi-supervised learning it is assumed that the labels are missing at random. This means that the unlabeled data is assumed to come from a distribution that is identically to the distribution generating the labeled examples, when we integrate over the the label. In many settings, this is not a realistic assumption. Unlabeled data may be used because they were easy to gather and this type of convenience sampling may introduce biases in the type of data that are gathered. Consider, for instance, the example of gathering documents downloaded from the web to improve the performance of a system that attempts to classify newspaper articles. The two underlying distributions are likely to be different. Biases may also be introduced through the labeling of objects, even if the objects themselves originate from some i.i.d. process. This could happen if objects with certain labels are easier to label than others, and therefore more likely to be labeled. 

Because the assumption of the identical distribution of the unlabeled data is in many cases not realistic, the semi-supervised learning setting is often an idealized version of the actual problem that needs to be solved. Related learning settings cover scenarios where we do take violations of this assumption into account. In general, we can often describe these settings as \emph{transfer learning} problems \cite{torrey2009transfer, Quinonero-Candela2009}, where the data which one learns from do not come from the distribution on which the final classifier will be applied. More specifically, when the unlabeled data come from the target distribution we are interested in, this is known as \emph{domain adaptation} \citep{Kouw2016,Cortes2011}.

One can expect these related learning settings to require even more prior information than the more restricted semi-supervised setting, since we somehow have to model the relationship between the labeled and the unlabeled distribution as well as learn from the unlabeled data. The projected estimators framework presented in this thesis can, in principle, be adapted to some of these related learning settings as well. As of yet, it is unclear how effective this will be. For instance, in the domain adaptation setting, on the one hand, the regular supervised solution may be expected to perform poorly, leading to potential large improvements when using the projected estimator. On the other hand, the conservative nature of this estimator may not lead to large improvements because substantive prior assumptions are likely needed to model the transfer between domains.

Overall, it is worthwhile to keep in mind that the semi-supervised problem may be an idealized version of the problem we face in many applications. The insights gained by studying the semi-supervised setting could be extended to scenarios where we make more appropriate assumptions about the process that led us to observe the labeled and unlabeled datasets.

\subsection{The Reinvention of Self-Learning}
Handling missing data in general and semi-supervised learning in particular is not a new problem \citep{Little2002}. In \Cref{chapter:optimistic} we have covered methods going back to the 1930s that implement some form of self-learning in the context of missing outcomes. Many procedures, in one form or another, use this general concept by using imputation steps for the unlabeled data, followed by optimization steps, to find a semi-supervised solution. Expectation Maximization \cite{Dempster1977} can be considered in this light, but also some approaches to solving Transductive SVMs \citep{Joachims1999}. Many graph based approaches can also be considered in this way \citep{Zhu2003}, where labels are propagated over the graph. What these approaches have in common is that the labels are treated as missing variables in an optimization function and the main problem is finding their value that minimizes this objective. This thesis has shown that alternatives are possible, by not including an additional term in the objective function, but rather using the unlabeled data in different ways, such as formulating constraints on the solution.

Reinventing self-learning and renaming it in the process has become somewhat of a tradition in semi-supervised learning research. So much so that, to some, semi-supervised learning has become synonymous to self-learning. Among others, self-learning is known in the literature as self-training \citep{Zhu2005}, Baum-Welch reestimation \citep{Elworthy1994}, Yarowsky's algorithm and more recently, pseudo-labeling \cite{Lee2013}.

While this is not a problem in and of itself, it is important to heed the lessons we learned in the past and resist the dream of thinking these unlabeled data will automatically be as valuable as labeled examples, or that they will be a panacea for all problems. If anything, this thesis shows getting the full use out of these data often requires modelling and making assumptions. After all, statistical machine learning is as much about the model, as it is about the data.

\subsection{The New Frontier}
While many issues remain, it is encouraging to see semi-supervised methods  are starting to get used on large scale problems \cite{Ravi2016}. Some of the assumptions discussed in the introduction appear to be useful in these real-world applications, using enormous amounts of unlabeled data. Moreover, semi-supervised learning research is not immune to the recent advances in effectively learning hierarchical architectures. Advances are being made by sharing properties of networks that learn to reconstruct inputs and networks that predict labels from inputs \cite{Rasmus2015} which suggests something akin to the manifold assumption is effective in their application domain. Or by learning to distinguish between the unlabeled objects and generated objects that are similar to but not like the classes we are trying to learn using generative adversarial networks \cite{Salimans2016}. These and other approaches have shown promising performance on image recognition tasks, using relatively few labeled objects. 

While the models are becoming more complex, the basic questions still remain the same. For what problems does this work and why? What assumptions do we need to make to guarantee the unlabeled data are useful? And why is it essentially impossible to do this for some problems and models and possible for others? Steps have been made in these areas, but leaps still remain.

\section{From Reproducibility to Replicability}
In part three of the thesis, we covered the reproducibility of results in the context of the research that we did in the chapters prior. We argued that reproducibility is important, and often requires little extra effort, or even a reduction in effort to the researcher, while having various advantages in scientific communication. Yet, we noted that ultimately the goal is replicability: being able to produce the same qualitative findings from scratch. We are aware the definitions we used in these chapters are but a starting point and are glad to see developments to make these more concrete. The issues are becoming especially pertinent for research involving large models trained on enormous datasets, where the financial or time investment of reproducing results can be prohibitive. While scientific communication is built on trust, it is also requires an ability to operationalize skepticism by reproducing and replicating claims. How we will deal with this as a scientific community is an open problem.

\section{On Conceptual Research}
Lastly, let me comment on the type of research project that the work presented in the prior chapters represents. As you might have noticed, it contains a small number of important theorems but no long, complex proofs. It presents interesting new approaches, but no large complex models. It presents experiments on archetypical simulated datasets and well-known benchmark datasets but no `state-of-the-art' results on groundbreaking new problems. And in doing so, I hope that most of all, it contains an interesting new perspective on the problem of semi-supervised learning. Rather than theoretical research, whose implications can be hard to relate to practice, or applied research, which can be too focused on the details of the problem at hand, the work in this thesis represents what I would refer to as conceptual research in pattern recognition. Many have noted the large gap between theory and practice in semi-supervised learning. We hope to have contributed to this fascinating topic. But many questions remain. Apart from the answering some questions about semi-supervised learning and bringing up new ones, I hope to have gotten across that as with many problems in machine learning, statistics and pattern recognition, the issues are not just computational, but statistical, conceptual and sometimes even epistemological in nature. The work has given me a better understanding of the problem of semi-supervised learning, and I hope to have gotten these insights across in this thesis.

